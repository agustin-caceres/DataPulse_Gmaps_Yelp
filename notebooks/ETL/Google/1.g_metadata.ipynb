{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio del Proceso ETL\n",
    "\n",
    "### Orden de Ejecución\n",
    "Este archivo es el primero en la secuencia de ejecución de los notebooks del proceso ETL para **Google**. Asegúrate de seguir el orden establecido para garantizar la correcta integración y procesamiento de los datos.\n",
    "\n",
    "### Fuentes de Datos\n",
    "Los datos se obtienen de archivos JSON que contienen información sobre negocios de Google Maps. Cada archivo representa un conjunto de datos relacionado con diferentes aspectos de los negocios, como nombres, direcciones, calificaciones y servicios ofrecidos.\n",
    "\n",
    "### Estructura de Datos\n",
    "Se ha realizado el proceso ETL en base al diagrama de entidad-relación (E/R) creado anteriormente, siguiendo el orden de tablas, tipos de datos e identificadores únicos. Esto asegura una comprensión clara de cómo se relacionan los datos entre sí y proporciona una estructura coherente para el diseño del esquema en la base de datos.\n",
    "\n",
    "### Tipo de Datos\n",
    "Los datos son considerados **Big Data** debido a su volumen y diversidad. Cada archivo JSON es tratado como un conjunto de datos que se procesará en el flujo ETL.\n",
    "\n",
    "### Almacenamiento de Archivos\n",
    "Los archivos JSON se encuentran en la siguiente ruta de Google Drive:\n",
    "https://drive.google.com/drive/folders/1Wf7YkxA0aHI3GpoHc9Nh8_scf5BbD4DA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias Necesarias \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los 11 archivos Jsons estaticos de Google, los juntamos en un solo archivo.\n",
    "list_sitios_path = [\n",
    "    'datasets/google/sitios/1.json',\n",
    "    'datasets/google/sitios/2.json',\n",
    "    'datasets/google/sitios/3.json',\n",
    "    'datasets/google/sitios/4.json',\n",
    "    'datasets/google/sitios/5.json',\n",
    "    'datasets/google/sitios/6.json',\n",
    "    'datasets/google/sitios/7.json',\n",
    "    'datasets/google/sitios/8.json',\n",
    "    'datasets/google/sitios/9.json',\n",
    "    'datasets/google/sitios/10.json',\n",
    "    'datasets/google/sitios/11.json'\n",
    "]\n",
    "\n",
    "for i in range(11):\n",
    "    df = pd.read_json(list_sitios_path[i], lines=True)\n",
    "    if i == 0:\n",
    "        g_sitios = df.copy()\n",
    "        del df\n",
    "    else:\n",
    "        g_sitios = pd.concat([g_sitios, df], axis=0, ignore_index=True)\n",
    "        del df\n",
    "\n",
    "# Eliminamos filas que repitan la clave primaria y unica        \n",
    "g_sitios = g_sitios.drop_duplicates(subset=['gmap_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Guardamos el conjunto de datos en Parquet para optimizacion de espacio, con los datos originales para un respaldo inicial.\n",
    "g_sitios.to_parquet('datasets/google/sitios/sitios_google_columnas_originales.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para descomponer la Lista de los Horarios\n",
    "def retornar_horario(campo:list[str], dia:str) -> str:\n",
    "    \"\"\" Función de apoyo a los campos que representan el horario de\n",
    "                         cada dia: monday, tuesday....sunday\n",
    "\n",
    "    Args:\n",
    "        campo (list[list]): lista de la columna `hours` \n",
    "        dia (str): dia de la semana a consultar en campo\n",
    "\n",
    "    Returns:\n",
    "        str: Horario del dia especifico que se consulta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for i in range(7):\n",
    "            if campo[i][0].lower() != dia.lower():\n",
    "                continue\n",
    "            buscado = campo[i][1]\n",
    "            break\n",
    "        return buscado\n",
    "    except:\n",
    "        return 'No Disponible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se Crea las Columnas de los Horarios\n",
    "\n",
    "g_sitios['monday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Monday'))\n",
    "\n",
    "g_sitios['tuesday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Tuesday'))\n",
    "\n",
    "g_sitios['wednesday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Wednesday'))\n",
    "\n",
    "g_sitios['thursday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Thursday'))\n",
    "\n",
    "g_sitios['friday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Friday'))\n",
    "\n",
    "g_sitios['saturday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Saturday'))\n",
    "\n",
    "g_sitios['sunday'] = g_sitios['hours'].apply(lambda x: retornar_horario(x, dia='Sunday'))\n",
    "\n",
    "g_sitios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora podemos eliminar la columna horarios.\n",
    "g_sitios.drop('hours', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva tabla relative_results\n",
    "relative_results = g_sitios[['gmap_id', 'relative_results']]\n",
    "# Desempaquetamos su información.\n",
    "relative_results = relative_results.explode('relative_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guaradamos la tabla desanidada que se conecta a travez de gmap_id con la tabla principal.\n",
    "relative_results.to_parquet('datasets/google/sitios/relative_results.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listo el analisis inicial de la tabla principal, pasamos al Notebook 2, donde estara el desanidado y normalizacion de las demas tablas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAentorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
