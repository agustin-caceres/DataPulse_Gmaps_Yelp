# Pipeline ETL de Yelp y Google en Airflow üöÄ

## Descripci√≥n General üìù
Este proyecto implementa un pipeline ETL (Extracci√≥n, Transformaci√≥n, Carga) utilizando Google Cloud Platform (GCP) y Apache Airflow. El objetivo es procesar y cargar los datos de Yelp y Google en BigQuery de manera automatizada, asegurando que los datos est√©n limpios y listos para el an√°lisis. Actualmente, el pipeline est√° configurado para procesar los datos de check-in de Yelp y almacenarlos en una tabla temporal en BigQuery antes de realizar transformaciones adicionales.

## Tecnolog√≠as Utilizadas üíª
- **Google Cloud Platform (GCP)**:
  - BigQuery para el almacenamiento y procesamiento de datos.
  - Google Cloud Storage (GCS) para almacenar los archivos fuente.
  - Google Composer para administrar la arquitectura de Airflow.
- **Apache Airflow**: Orquestaci√≥n del pipeline ETL.
- **Python**: Desarrollo de funciones auxiliares y transformaci√≥n de datos.

## Estructura del Proyecto üìÇ
- **DAG**:
    - `DAG_yelp_etl.py:` Este archivo contiene el DAG principal que coordina las tareas de creaci√≥n de tablas, extracci√≥n de datos y carga en BigQuery.
- **M√≥dulos Auxiliares**:
  - `bigquery_utils.py`: Incluye funciones auxiliares para interactuar con BigQuery, como la creaci√≥n de tablas, carga de DataFrames, y la eliminaci√≥n de tablas temporales.
  - `extract_data_yelp.py`: Contiene funciones para la extracci√≥n y transformaci√≥n espec√≠ficas de los datasets.
- **Transformaciones**:
    - Transformaciones espec√≠ficas para distintos archivos (por ejemplo, checkin.json) se gestionan mediante un diccionario en bigquery_utils.py, lo que permite agregar reglas de transformaci√≥n espec√≠ficas para otros archivos de manera sencilla.

## Estructura del DAG üóÇÔ∏è

1. **Inicio**:
    - `Inicio:` Un `DummyOperator` que marca el comienzo del DAG para facilitar la visualizaci√≥n en Airflow.
2. **Creaci√≥n de Tabla Temporal**:
    - `crear_tabla_temporal:` Tarea encargada de crear una tabla temporal en BigQuery para almacenar los datos de los archivos en Storage con el esquema adecuado. Esto permite realizar transformaciones adicionales en BigQuery antes de mover los datos a la tabla final.
3. **Carga de Datos**:
    - `cargar_archivo_en_tabla_temporal:` Esta tarea extrae el archivo desde Google Cloud Storage (GCS), aplica las transformaciones necesarias y carga los datos en la tabla temporal en BigQuery para luego realizar las transformaciones y mover los datos a la tabla final.
4. **Fin**:
    - `fin:` Un `DummyOperator` que marca el fin del DAG.

## Esquema de la Tabla Temporal üìã

La tabla temporal `checkin_temp` contiene los siguientes campos:
- **business_id**: Identificador del negocio (STRING).
- **date**: Fecha y hora del check-in en formato `TIMESTAMP`.

## Funcionalidades y Detalles T√©cnicos ‚öôÔ∏è
- **Diccionario de Transformaciones**:
  - En `bigquery_utils.py` se encuentra un diccionario `transformaciones` que permite asociar cada archivo con su respectiva funci√≥n de transformaci√≥n. Esto facilita la extensi√≥n del pipeline a otros archivos, ya que solo se necesita crear una funci√≥n de transformaci√≥n y a√±adirla al diccionario.
- **Funci√≥n de Transformaci√≥n `transformar_checkin`**:
  - Esta funci√≥n procesa el campo `date` en `checkin.json`, separando las fechas en filas individuales y convirtiendo cada valor en formato TIMESTAMP. La funci√≥n asegura que las fechas est√©n en el formato `YYYY-MM-DD HH:MM:SS` antes de la carga en BigQuery.
- **Validaciones y Control de Errores**:
  - El pipeline incluye validaciones como verificar si el DataFrame est√° vac√≠o antes de cargarlo en BigQuery.
  - En caso de error durante la extracci√≥n o carga, se utilizan bloques `try-except` para manejar las excepciones y permitir que el pipeline contin√∫e sin interrupciones graves.

## Pr√≥ximos Pasos üîú
- **Implementaci√≥n de Transformaci√≥n en BigQuery**:
  - Realizar transformaciones adicionales en BigQuery sobre la tabla temporal (`checkin_temp`) antes de mover los datos a la tabla final.
  - Eliminar la tabla temporal una vez que los datos hayan sido transformados y cargados en la tabla final, para optimizar el uso de recursos.
- **Automatizaci√≥n para Otros Datasets**:
  - Extender el pipeline para procesar otros archivos de Yelp y Google, agregando sus transformaciones espec√≠ficas al diccionario `transformaciones`.
- **Automatizaci√≥n del Pipeline**:
  - Configurar sensores o triggers en Airflow para que el pipeline se active autom√°ticamente al detectar nuevos archivos en GCS.
- **Monitoreo y Alertas**:
  - Implementar alertas y notificaciones en caso de fallos en alguna de las tareas del DAG, utilizando los servicios de Airflow y GCP.

## Posibles Mejoras y Consideraciones Futuras üåü
- **Optimizaci√≥n de Transformaciones en BigQuery**:
  - A medida que se agreguen m√°s datos, puede ser necesario optimizar las consultas de transformaci√≥n en BigQuery para reducir costos y tiempo de procesamiento.
- **Documentaci√≥n y Comentarios en el C√≥digo**:
  - Es importante mantener la documentaci√≥n del c√≥digo y actualizar el markdown conforme avancemos en el proyecto. Esto facilitar√° la colaboraci√≥n en equipo y la comprensi√≥n de los cambios realizados.
- **Manejo de Versiones**:
  - Considerar la posibilidad de versionar el c√≥digo y los datasets para mantener un historial de cambios y facilitar la reversi√≥n en caso de problemas.

## Notas Finales üìù
Este markdown documenta el progreso actual del pipeline y proporciona una gu√≠a sobre la arquitectura, el flujo de trabajo y las consideraciones clave. A medida que avancemos en el proyecto, este documento se actualizar√° para reflejar nuevos desarrollos y decisiones de dise√±o.

